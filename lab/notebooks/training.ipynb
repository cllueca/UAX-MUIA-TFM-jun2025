{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builtins\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "# Installed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# Types\n",
    "from typing import (\n",
    "    Tuple,\n",
    "    Any\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25\n"
     ]
    }
   ],
   "source": [
    "# Set path for custom imports\n",
    "project_root = os.path.abspath('..')\n",
    "print(project_root)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "from src.dataloader import TorchDataLoader\n",
    "from src.unet import (\n",
    "    UNet3D,\n",
    "    AttentionUnet3D\n",
    ")\n",
    "from src.vit import (\n",
    "    VisionTransformer\n",
    ")\n",
    "from src.callbacks.logger import (\n",
    "    LogFileLogger,\n",
    "    CSVLogger\n",
    ")\n",
    "from src.callbacks.earlystopping import EarlyStopping\n",
    "from src.callbacks.modelcheckpoint import ModelCheckpoint\n",
    "from src.callbacks.reducelr import ReduceLROnPlateau\n",
    "from src.train_logic import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch detects 1 GPU(s): NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"PyTorch detects {torch.cuda.device_count()} GPU(s): {', '.join(torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count()))}\" \n",
    "    if torch.cuda.is_available() \n",
    "    else \"PyTorch can't find any GPU\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD = \"\\033[1m\"      # Bold\n",
    "ITALIC = \"\\033[3m\"    # Italic\n",
    "RESET = \"\\033[0m\"     # Reset stdout modifications\n",
    "\n",
    "DATA_DIR_PATH = Path('/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC/')\n",
    "\n",
    "IMAGE_CUT_OPTIONS = {\n",
    "    1: 'axial',\n",
    "    2: 'coronal',\n",
    "    3: 'sagittal'\n",
    "}\n",
    "\n",
    "MODEL_SAVE_OPTIONS = {\n",
    "    1: 'state_dict',\n",
    "    2: 'complete',\n",
    "    3: 'with_params'\n",
    "}\n",
    "\n",
    "MODEL_TYPE = {\n",
    "    1: 'unet-original',\n",
    "    2: 'unet-attention',\n",
    "    3: 'vit'\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_configurations(model_config: dict[str, Any], data_config: dict[str, Any]) -> None:\n",
    "    \"\"\"Show data and model configurations\"\"\"\n",
    "    print(\"=== Settings ===\")\n",
    "    print(f\"{BOLD} - Data Directory Path:{RESET:>5} {ITALIC}{DATA_DIR_PATH}{RESET}\")\n",
    "    print(f\"{BOLD} - Using device:{RESET:>11} {ITALIC} {DEVICE}{RESET}\")\n",
    "    \n",
    "    print(\"\\n=== Data Configuration ===\")\n",
    "    max_data_key_len = max(len(key) for key in data_config.keys())\n",
    "    for key, value in data_config.items():\n",
    "        print(f\"{BOLD} - {key + ':':<{max_data_key_len + 2}}{RESET} {ITALIC}{value}{RESET}\")\n",
    "    \n",
    "    print(\"\\n=== Model Configuration ===\")\n",
    "    max_model_key_len = max(len(key) for key in model_config.keys())\n",
    "    for key, value in model_config.items():\n",
    "        print(f\"{BOLD} - {key + ':':<{max_model_key_len + 2}}{RESET} {ITALIC}{value}{RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model_config: dict[str, Any], data_config: dict[str, Any]) -> Tuple[DataLoader, DataLoader]:\n",
    "    dataloader = TorchDataLoader(\n",
    "        data_dir_path=DATA_DIR_PATH,\n",
    "        data_config=data_config,\n",
    "        model_config=model_config\n",
    "    )\n",
    "\n",
    "    return dataloader.load_train_data(), dataloader.load_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(model_config: dict[str, Any], train_loader: DataLoader, val_loader: DataLoader) -> dict[str, Any]:\n",
    "    # Create model\n",
    "    if model_config['model_type'] == 'unet-original':\n",
    "        model = UNet3D(model_config)\n",
    "    elif model_config['model_type'] == 'unet-attention':\n",
    "        model = AttentionUnet3D(model_config)\n",
    "    elif model_config['model_type'] == 'vit':\n",
    "        model = VisionTransformer(model_config)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_config['model_type']}\")\n",
    "\n",
    "    model.display_summary()\n",
    "\n",
    "    if model_config.get('web_view', False):\n",
    "        model.view_model_graph(browser_view=True)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_config['learning_rate'])\n",
    "    criterion = nn.L1Loss()  # Mean Absolute Error (MAE)\n",
    "\n",
    "    training_logger = LogFileLogger(model_config=model_config)\n",
    "\n",
    "    # Setup callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            model_config=model_config,\n",
    "            verbose=True,\n",
    "            save_best_only=True,\n",
    "            logger=training_logger\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            model_config=model_config,\n",
    "            logger=training_logger\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            model_config=model_config,\n",
    "            restore_best_weights=False,\n",
    "            logger=training_logger\n",
    "        ),\n",
    "        CSVLogger(\n",
    "            model_config=model_config,\n",
    "            logger=training_logger\n",
    "        ),\n",
    "        training_logger\n",
    "    ]\n",
    "\n",
    "    # Train the model\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=DEVICE,\n",
    "        config=model_config,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    " \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AVISO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los logs de entrenamiento de la U-net original no están en este notebook porque la celda se volvió a ejecutar por error.\n",
    "\n",
    "Los logs de entrenamiento del ViT no se ven completos en este notebook.\n",
    "\n",
    "Ambos logs pueden encontrarse respectivamente en la carpeta de cada modelo:\n",
    "\n",
    "- **U-net**: *lab/models/Unet1/logs/model_train.log*\n",
    "\n",
    "- **ViT**: *lab/models/vit_pruebas_2/logs/model_train.log*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Normal U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Settings ===\n",
      "\u001b[1m - Data Directory Path: \u001b[0m \u001b[3m/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC\u001b[0m\n",
      "\u001b[1m - Using device:       \u001b[0m \u001b[3m cuda\u001b[0m\n",
      "\n",
      "=== Data Configuration ===\n",
      "\u001b[1m - axis_cut:  \u001b[0m \u001b[3maxial\u001b[0m\n",
      "\u001b[1m - first_cut: \u001b[0m \u001b[3m0\u001b[0m\n",
      "\u001b[1m - last_cut:  \u001b[0m \u001b[3m127\u001b[0m\n",
      "\u001b[1m - layer_qty: \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - normalize: \u001b[0m \u001b[3mFalse\u001b[0m\n",
      "\n",
      "=== Model Configuration ===\n",
      "\u001b[1m - name:                    \u001b[0m \u001b[3mUnet1\u001b[0m\n",
      "\u001b[1m - model_type:              \u001b[0m \u001b[3munet-original\u001b[0m\n",
      "\u001b[1m - input_shape:             \u001b[0m \u001b[3m(1, 8, 128, 128)\u001b[0m\n",
      "\u001b[1m - input_shape_graph:       \u001b[0m \u001b[3m(8, 1, 8, 128, 128)\u001b[0m\n",
      "\u001b[1m - batch_size:              \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - min_feature_map_dim:     \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - layer_filters:           \u001b[0m \u001b[3m[64, 128, 256, 512, 1024]\u001b[0m\n",
      "\u001b[1m - layer_dropouts:          \u001b[0m \u001b[3m[0.1, 0.1, 0.2, 0.2, 0.3]\u001b[0m\n",
      "\u001b[1m - num_epochs:              \u001b[0m \u001b[3m200\u001b[0m\n",
      "\u001b[1m - learning_rate:           \u001b[0m \u001b[3m0.0001\u001b[0m\n",
      "\u001b[1m - early_stopping_patience: \u001b[0m \u001b[3m20\u001b[0m\n",
      "\u001b[1m - reduce_lr_patience:      \u001b[0m \u001b[3m5\u001b[0m\n",
      "\u001b[1m - lr_reduce_factor:        \u001b[0m \u001b[3m0.1\u001b[0m\n",
      "\u001b[1m - min_lr:                  \u001b[0m \u001b[3m1e-12\u001b[0m\n",
      "\u001b[1m - save_method:             \u001b[0m \u001b[3mcomplete\u001b[0m\n",
      "\u001b[1m - web_view:                \u001b[0m \u001b[3mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Unet1'\n",
    "batch_size = 8\n",
    "layer_qty = 8\n",
    "data_config = {\n",
    "    'axis_cut': IMAGE_CUT_OPTIONS[1],\n",
    "    'first_cut': 0,\n",
    "    'last_cut': 127,\n",
    "    'layer_qty': layer_qty,\n",
    "    'normalize': False\n",
    "}\n",
    "model_config = {\n",
    "    'name': model_name,\n",
    "    'model_type': MODEL_TYPE[1],\n",
    "    'input_shape': (1, layer_qty, 128, 128),\n",
    "    'input_shape_graph': (batch_size, 1, layer_qty, 128, 128),\n",
    "    'batch_size': batch_size,\n",
    "    'min_feature_map_dim': 8,\n",
    "    'layer_filters': [64, 128, 256, 512, 1024],\n",
    "    'layer_dropouts': [0.1, 0.1, 0.2, 0.2, 0.3],\n",
    "    'num_epochs': 200,\n",
    "    'learning_rate': 1e-4,\n",
    "    'early_stopping_patience': 20,\n",
    "    'reduce_lr_patience': 5,\n",
    "    'lr_reduce_factor': 0.1,\n",
    "    'min_lr': 1e-12,\n",
    "    'save_method': MODEL_SAVE_OPTIONS[2],\n",
    "    'web_view': True\n",
    "}\n",
    "\n",
    "display_configurations(model_config, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/Unet1/config/data_config.json'...\n",
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/Unet1/config/model_config.json'...\n",
      "Loading training data...\n",
      " ==  Loading train images set  ==\n",
      "\t- Loading 28 images from '/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC/fold1' ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m history \u001b[38;5;241m=\u001b[39m create_and_train_model(model_config, train_loader, val_loader)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Clean environment - Delete vars and free GPU memory (there is still something takin like 6% of the GPU V-RAM)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(model_config, data_config)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data\u001b[39m(model_config, data_config):\n\u001b[1;32m      2\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m TorchDataLoader(\n\u001b[1;32m      3\u001b[0m         data_dir_path\u001b[38;5;241m=\u001b[39mDATA_DIR_PATH,\n\u001b[1;32m      4\u001b[0m         data_config\u001b[38;5;241m=\u001b[39mdata_config,\n\u001b[1;32m      5\u001b[0m         model_config\u001b[38;5;241m=\u001b[39mmodel_config\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dataloader\u001b[38;5;241m.\u001b[39mload_validation_data()\n",
      "File \u001b[0;32m~/jhernandez/3d-notebooks/3d/9jun25/9jun25/src/dataloader.py:326\u001b[0m, in \u001b[0;36mTorchDataLoader.load_train_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03mLoad and prepare training data.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m    DataLoader: Training data loader\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 326\u001b[0m train_inputs, train_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Add channel dimension (at position 1)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m train_inputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(train_inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/jhernandez/3d-notebooks/3d/9jun25/9jun25/src/dataloader.py:260\u001b[0m, in \u001b[0;36mTorchDataLoader._load_data\u001b[0;34m(self, is_test)\u001b[0m\n\u001b[1;32m    257\u001b[0m label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(labels_path, img_file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_NAC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Load images and labels\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m image_data, image_aff, image_hdr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_nifti_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m label_data, label_aff, label_hdr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_nifti_image(label_path)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Create empty np matrix\u001b[39;00m\n",
      "File \u001b[0;32m~/jhernandez/3d-notebooks/3d/9jun25/9jun25/src/dataloader.py:151\u001b[0m, in \u001b[0;36mTorchDataLoader._load_nifti_image\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     img \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(image_path)\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, img\u001b[38;5;241m.\u001b[39maffine, img\u001b[38;5;241m.\u001b[39mheader\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m nib\u001b[38;5;241m.\u001b[39mfilebasedimages\u001b[38;5;241m.\u001b[39mImageFileError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m nib\u001b[38;5;241m.\u001b[39mfilebasedimages\u001b[38;5;241m.\u001b[39mImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading NIfTI image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/jhernandez/direct_venv/lib/python3.10/site-packages/nibabel/dataobj_images.py:374\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[0;34m(self, caching, dtype)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/jhernandez/direct_venv/lib/python3.10/site-packages/nibabel/arrayproxy.py:454\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/jhernandez/direct_venv/lib/python3.10/site-packages/nibabel/arrayproxy.py:421\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    419\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/jhernandez/direct_venv/lib/python3.10/site-packages/nibabel/arrayproxy.py:391\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m canonical_slicers(\n\u001b[1;32m    388\u001b[0m     (), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m ):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[1;32m    401\u001b[0m         fileobj,\n\u001b[1;32m    402\u001b[0m         slicer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m         lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock,\n\u001b[1;32m    408\u001b[0m     )\n",
      "File \u001b[0;32m~/jhernandez/direct_venv/lib/python3.10/site-packages/nibabel/volumeutils.py:467\u001b[0m, in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    466\u001b[0m     data_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[0;32m--> 467\u001b[0m     n_read \u001b[38;5;241m=\u001b[39m \u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     needs_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:494\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_member \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT_BUFFER_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mdecompress(buf, size)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:88\u001b[0m, in \u001b[0;36m_PaddedFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read \u001b[38;5;241m+\u001b[39m size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length:\n\u001b[1;32m     90\u001b[0m         read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = load_data(model_config, data_config)\n",
    "\n",
    "history = create_and_train_model(model_config, train_loader, val_loader)\n",
    "\n",
    "# Clean environment - Delete vars and free GPU memory (there is still something takin like 6% of the GPU V-RAM)\n",
    "del history\n",
    "del model_name\n",
    "del batch_size\n",
    "del data_config\n",
    "del model_config\n",
    "del train_loader\n",
    "del val_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - U-Net Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Settings ===\n",
      "\u001b[1m - Data Directory Path: \u001b[0m \u001b[3m/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC\u001b[0m\n",
      "\u001b[1m - Using device:       \u001b[0m \u001b[3m cuda\u001b[0m\n",
      "\n",
      "=== Data Configuration ===\n",
      "\u001b[1m - axis_cut:  \u001b[0m \u001b[3maxial\u001b[0m\n",
      "\u001b[1m - first_cut: \u001b[0m \u001b[3m0\u001b[0m\n",
      "\u001b[1m - last_cut:  \u001b[0m \u001b[3m127\u001b[0m\n",
      "\u001b[1m - layer_qty: \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - normalize: \u001b[0m \u001b[3mFalse\u001b[0m\n",
      "\n",
      "=== Model Configuration ===\n",
      "\u001b[1m - name:                    \u001b[0m \u001b[3mattention1\u001b[0m\n",
      "\u001b[1m - model_type:              \u001b[0m \u001b[3munet-attention\u001b[0m\n",
      "\u001b[1m - input_shape:             \u001b[0m \u001b[3m(1, 8, 128, 128)\u001b[0m\n",
      "\u001b[1m - input_shape_graph:       \u001b[0m \u001b[3m(8, 1, 8, 128, 128)\u001b[0m\n",
      "\u001b[1m - batch_size:              \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - min_feature_map_dim:     \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - layer_filters:           \u001b[0m \u001b[3m[64, 128, 256, 512, 1024]\u001b[0m\n",
      "\u001b[1m - layer_dropouts:          \u001b[0m \u001b[3m[0.1, 0.1, 0.2, 0.2, 0.3]\u001b[0m\n",
      "\u001b[1m - num_epochs:              \u001b[0m \u001b[3m200\u001b[0m\n",
      "\u001b[1m - learning_rate:           \u001b[0m \u001b[3m0.0001\u001b[0m\n",
      "\u001b[1m - early_stopping_patience: \u001b[0m \u001b[3m20\u001b[0m\n",
      "\u001b[1m - reduce_lr_patience:      \u001b[0m \u001b[3m5\u001b[0m\n",
      "\u001b[1m - lr_reduce_factor:        \u001b[0m \u001b[3m0.1\u001b[0m\n",
      "\u001b[1m - min_lr:                  \u001b[0m \u001b[3m1e-12\u001b[0m\n",
      "\u001b[1m - save_method:             \u001b[0m \u001b[3mcomplete\u001b[0m\n",
      "\u001b[1m - web_view:                \u001b[0m \u001b[3mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = 'attention1'\n",
    "batch_size = 8\n",
    "layer_qty = 8\n",
    "data_config = {\n",
    "    'axis_cut': IMAGE_CUT_OPTIONS[1],\n",
    "    'first_cut': 0,\n",
    "    'last_cut': 127,\n",
    "    'layer_qty': layer_qty,\n",
    "    'normalize': False\n",
    "}\n",
    "model_config = {\n",
    "    'name': model_name,\n",
    "    'model_type': MODEL_TYPE[2],\n",
    "    'input_shape': (1, layer_qty, 128, 128),\n",
    "    'input_shape_graph': (batch_size, 1, layer_qty, 128, 128),\n",
    "    'batch_size': batch_size,\n",
    "    'min_feature_map_dim': 8,\n",
    "    'layer_filters': [64, 128, 256, 512, 1024],\n",
    "    'layer_dropouts': [0.1, 0.1, 0.2, 0.2, 0.3],\n",
    "    'num_epochs': 200,\n",
    "    'learning_rate': 1e-4,\n",
    "    'early_stopping_patience': 20,\n",
    "    'reduce_lr_patience': 5,\n",
    "    'lr_reduce_factor': 0.1,\n",
    "    'min_lr': 1e-12,\n",
    "    'save_method': MODEL_SAVE_OPTIONS[2],\n",
    "    'web_view': True\n",
    "}\n",
    "\n",
    "display_configurations(model_config, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/config/data_config.json'...\n",
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/config/model_config.json'...\n",
      "Loading training data...\n",
      " ==  Loading train images set  ==\n",
      "\t- Loading 28 images from '/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC/fold1' ...\n",
      "\t- Could only load 28 images. Detected 0 outlier(s)\n",
      "\t- Pixels value range: [0.0, 0.22]\n",
      "Train inputs shape: (448, 1, 8, 128, 128)\n",
      "Train targets shape: (448, 1, 8, 128, 128)\n",
      "Training loader generated. Batch size: 8\n",
      "== Train set loader ==\n",
      "Common batch shape (num_batches / batch_size, channels, depth / num_layers, height, width):\n",
      " - Inputs: torch.Size([8, 1, 8, 128, 128])\n",
      " - Targets: torch.Size([8, 1, 8, 128, 128])\n",
      "All batches have the same size\n",
      "Loading test data for validation...\n",
      " ==  Loading test images set  ==\n",
      "\t- Loading 8 images from '/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC/fold1' ...\n",
      "\t- Could only load 6 images. Detected 2 outlier(s)\n",
      "\t- Pixels value range: [0.0, 0.23]\n",
      "Splitting test set in half, the second half will be used for validation...\n",
      "Validation inputs shape: (48, 1, 8, 128, 128)\n",
      "Validation targets shape: (48, 1, 8, 128, 128)\n",
      "Validation loader generated. Batch size: 8\n",
      "== Validation set loader ==\n",
      "Common batch shape (num_batches / batch_size, channels, depth / num_layers, height, width):\n",
      " - Inputs: torch.Size([8, 1, 8, 128, 128])\n",
      " - Targets: torch.Size([8, 1, 8, 128, 128])\n",
      "All batches have the same size\n",
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/config/model_config.json'...\n",
      "Using 4 blocks for Attention U-Net based on input dimensions (128, 128)\n",
      "\n",
      "Attention U-Net Model Summary:\n",
      "Total trainable parameters: 87,864,813\n",
      "LogFileLogger(filepath=/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/logs/model_train.log, flush_interval=1)\n",
      "ModelCheckpoint(filepath=/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth, monitor=val_loss, verbose=True, save_best_only='True', mode=min, save_method=complete)\n",
      "ReduceLROnPlateau(optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), mode=min, factor=0.1, patience='5', verbose=False, min_lr=1e-12)\n",
      "EarlyStopping(patience=20, verbose=False, delta=0.0, filepath='/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/checkpoints/attention1.pt', restore_best_weights=False)\n",
      "CSVLogger(filepath=/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/logs/model_train.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/xdg-open: 882: /home/promise/.vscode-server/cli/servers/Stable-17baf841131aa23349f217ca7c570c76ee87b957/server/bin/helpers/browser.sh: not found\n",
      "/usr/bin/xdg-open: 882: /home/promise/.vscode-server/cli/servers/Stable-17baf841131aa23349f217ca7c570c76ee87b957/server/bin/helpers/browser.sh: not found\n",
      "xdg-open: no method available for opening '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/graph/attention1.pdf'\n",
      "Epoch 1/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.265, mae=0.265, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - 12.70s - loss: 0.2655 - mae: 0.2655 - val_loss: 0.2054 - val_mae: 0.2054 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.20539, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.201, mae=0.201, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 - 12.70s - loss: 0.2008 - mae: 0.2008 - val_loss: 0.1855 - val_mae: 0.1855 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 2: val_loss improved from 0.20539 to 0.18549, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.173, mae=0.173, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200 - 12.69s - loss: 0.1733 - mae: 0.1733 - val_loss: 0.1583 - val_mae: 0.1583 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 3: val_loss improved from 0.18549 to 0.15834, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.16, mae=0.16, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200 - 12.73s - loss: 0.1597 - mae: 0.1597 - val_loss: 0.1501 - val_mae: 0.1501 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 4: val_loss improved from 0.15834 to 0.15006, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.14, mae=0.14, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200 - 12.70s - loss: 0.1398 - mae: 0.1398 - val_loss: 0.1297 - val_mae: 0.1297 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 5: val_loss improved from 0.15006 to 0.12966, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.124, mae=0.124, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200 - 12.71s - loss: 0.1238 - mae: 0.1238 - val_loss: 0.1231 - val_mae: 0.1231 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 6: val_loss improved from 0.12966 to 0.12313, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.112, mae=0.112, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200 - 12.69s - loss: 0.1124 - mae: 0.1124 - val_loss: 0.1047 - val_mae: 0.1047 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 7: val_loss improved from 0.12313 to 0.10466, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.1, mae=0.1, lr=0.0001]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200 - 12.69s - loss: 0.1003 - mae: 0.1003 - val_loss: 0.0907 - val_mae: 0.0907 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 8: val_loss improved from 0.10466 to 0.09068, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0897, mae=0.0897, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200 - 12.71s - loss: 0.0897 - mae: 0.0897 - val_loss: 0.0951 - val_mae: 0.0951 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0807, mae=0.0807, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 - 12.70s - loss: 0.0807 - mae: 0.0807 - val_loss: 0.0870 - val_mae: 0.0870 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 10: val_loss improved from 0.09068 to 0.08704, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0779, mae=0.0779, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200 - 12.67s - loss: 0.0779 - mae: 0.0779 - val_loss: 0.0775 - val_mae: 0.0775 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 11: val_loss improved from 0.08704 to 0.07749, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.069, mae=0.069, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200 - 12.68s - loss: 0.0690 - mae: 0.0690 - val_loss: 0.0635 - val_mae: 0.0635 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 12: val_loss improved from 0.07749 to 0.06347, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.0623, mae=0.0623, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200 - 12.74s - loss: 0.0623 - mae: 0.0623 - val_loss: 0.0616 - val_mae: 0.0616 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 13: val_loss improved from 0.06347 to 0.06156, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0563, mae=0.0563, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200 - 12.71s - loss: 0.0563 - mae: 0.0563 - val_loss: 0.0524 - val_mae: 0.0524 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 14: val_loss improved from 0.06156 to 0.05245, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.0527, mae=0.0527, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200 - 12.74s - loss: 0.0527 - mae: 0.0527 - val_loss: 0.0548 - val_mae: 0.0548 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0498, mae=0.0498, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200 - 12.68s - loss: 0.0498 - mae: 0.0498 - val_loss: 0.0505 - val_mae: 0.0505 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 16: val_loss improved from 0.05245 to 0.05050, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0445, mae=0.0445, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200 - 12.71s - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0430 - val_mae: 0.0430 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 17: val_loss improved from 0.05050 to 0.04304, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0425, mae=0.0425, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200 - 12.71s - loss: 0.0425 - mae: 0.0425 - val_loss: 0.0442 - val_mae: 0.0442 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0387, mae=0.0387, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200 - 12.67s - loss: 0.0387 - mae: 0.0387 - val_loss: 0.0414 - val_mae: 0.0414 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 19: val_loss improved from 0.04304 to 0.04142, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0373, mae=0.0373, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200 - 12.72s - loss: 0.0373 - mae: 0.0373 - val_loss: 0.0402 - val_mae: 0.0402 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 20: val_loss improved from 0.04142 to 0.04020, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0334, mae=0.0334, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200 - 12.73s - loss: 0.0334 - mae: 0.0334 - val_loss: 0.0350 - val_mae: 0.0350 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 21: val_loss improved from 0.04020 to 0.03497, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0319, mae=0.0319, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200 - 12.72s - loss: 0.0319 - mae: 0.0319 - val_loss: 0.0352 - val_mae: 0.0352 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.03, mae=0.03, lr=0.0001]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200 - 12.71s - loss: 0.0300 - mae: 0.0300 - val_loss: 0.0303 - val_mae: 0.0303 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 23: val_loss improved from 0.03497 to 0.03033, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.027, mae=0.027, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200 - 12.74s - loss: 0.0270 - mae: 0.0270 - val_loss: 0.0305 - val_mae: 0.0305 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0264, mae=0.0264, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200 - 12.72s - loss: 0.0264 - mae: 0.0264 - val_loss: 0.0288 - val_mae: 0.0288 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 25: val_loss improved from 0.03033 to 0.02882, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 100%|██████████| 56/56 [00:11<00:00,  4.80it/s, loss=0.0259, mae=0.0259, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200 - 12.75s - loss: 0.0259 - mae: 0.0259 - val_loss: 0.0290 - val_mae: 0.0290 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0242, mae=0.0242, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200 - 12.67s - loss: 0.0242 - mae: 0.0242 - val_loss: 0.0272 - val_mae: 0.0272 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 27: val_loss improved from 0.02882 to 0.02724, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.0229, mae=0.0229, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200 - 12.75s - loss: 0.0229 - mae: 0.0229 - val_loss: 0.0262 - val_mae: 0.0262 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 28: val_loss improved from 0.02724 to 0.02625, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0213, mae=0.0213, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200 - 12.73s - loss: 0.0213 - mae: 0.0213 - val_loss: 0.0251 - val_mae: 0.0251 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 29: val_loss improved from 0.02625 to 0.02514, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0209, mae=0.0209, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200 - 12.71s - loss: 0.0209 - mae: 0.0209 - val_loss: 0.0219 - val_mae: 0.0219 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 30: val_loss improved from 0.02514 to 0.02186, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.02, mae=0.02, lr=0.0001]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200 - 12.69s - loss: 0.0200 - mae: 0.0200 - val_loss: 0.0217 - val_mae: 0.0217 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 31: val_loss improved from 0.02186 to 0.02166, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200: 100%|██████████| 56/56 [00:11<00:00,  4.80it/s, loss=0.0187, mae=0.0187, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200 - 12.76s - loss: 0.0187 - mae: 0.0187 - val_loss: 0.0227 - val_mae: 0.0227 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0172, mae=0.0172, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200 - 12.69s - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0206 - val_mae: 0.0206 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 33: val_loss improved from 0.02166 to 0.02059, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0172, mae=0.0172, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200 - 12.74s - loss: 0.0172 - mae: 0.0172 - val_loss: 0.0191 - val_mae: 0.0191 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 34: val_loss improved from 0.02059 to 0.01905, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.016, mae=0.016, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200 - 12.72s - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0197 - val_mae: 0.0197 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.016, mae=0.016, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200 - 12.71s - loss: 0.0160 - mae: 0.0160 - val_loss: 0.0189 - val_mae: 0.0189 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 36: val_loss improved from 0.01905 to 0.01891, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0151, mae=0.0151, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200 - 12.72s - loss: 0.0151 - mae: 0.0151 - val_loss: 0.0204 - val_mae: 0.0204 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0144, mae=0.0144, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200 - 12.68s - loss: 0.0144 - mae: 0.0144 - val_loss: 0.0222 - val_mae: 0.0222 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.014, mae=0.014, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200 - 12.70s - loss: 0.0140 - mae: 0.0140 - val_loss: 0.0193 - val_mae: 0.0193 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.013, mae=0.013, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200 - 12.67s - loss: 0.0130 - mae: 0.0130 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.012, mae=0.012, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200 - 12.68s - loss: 0.0120 - mae: 0.0120 - val_loss: 0.0167 - val_mae: 0.0167 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 41: val_loss improved from 0.01891 to 0.01671, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.0121, mae=0.0121, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200 - 12.74s - loss: 0.0121 - mae: 0.0121 - val_loss: 0.0169 - val_mae: 0.0169 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0117, mae=0.0117, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200 - 12.67s - loss: 0.0117 - mae: 0.0117 - val_loss: 0.0162 - val_mae: 0.0162 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 43: val_loss improved from 0.01671 to 0.01624, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0122, mae=0.0122, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200 - 12.70s - loss: 0.0122 - mae: 0.0122 - val_loss: 0.0159 - val_mae: 0.0159 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 44: val_loss improved from 0.01624 to 0.01589, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.0112, mae=0.0112, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200 - 12.72s - loss: 0.0112 - mae: 0.0112 - val_loss: 0.0155 - val_mae: 0.0155 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 45: val_loss improved from 0.01589 to 0.01549, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0108, mae=0.0108, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200 - 12.73s - loss: 0.0108 - mae: 0.0108 - val_loss: 0.0178 - val_mae: 0.0178 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0105, mae=0.0105, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200 - 12.74s - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0141 - val_mae: 0.0141 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 47: val_loss improved from 0.01549 to 0.01410, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0105, mae=0.0105, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200 - 12.72s - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0145 - val_mae: 0.0145 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00948, mae=0.00948, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200 - 12.69s - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0149 - val_mae: 0.0149 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0101, mae=0.0101, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200 - 12.67s - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0148 - val_mae: 0.0148 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00891, mae=0.00891, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200 - 12.73s - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0138 - val_mae: 0.0138 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 51: val_loss improved from 0.01410 to 0.01383, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00873, mae=0.00873, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200 - 12.70s - loss: 0.0087 - mae: 0.0087 - val_loss: 0.0132 - val_mae: 0.0132 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 52: val_loss improved from 0.01383 to 0.01321, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00879, mae=0.00879, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200 - 12.74s - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0133 - val_mae: 0.0133 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00839, mae=0.00839, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200 - 12.73s - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0136 - val_mae: 0.0136 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00924, mae=0.00924, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200 - 12.69s - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0140 - val_mae: 0.0140 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.00893, mae=0.00893, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200 - 12.70s - loss: 0.0089 - mae: 0.0089 - val_loss: 0.0146 - val_mae: 0.0146 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00791, mae=0.00791, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200 - 12.69s - loss: 0.0079 - mae: 0.0079 - val_loss: 0.0131 - val_mae: 0.0131 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 57: val_loss improved from 0.01321 to 0.01312, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.00838, mae=0.00838, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200 - 12.70s - loss: 0.0084 - mae: 0.0084 - val_loss: 0.0138 - val_mae: 0.0138 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00803, mae=0.00803, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200 - 12.67s - loss: 0.0080 - mae: 0.0080 - val_loss: 0.0124 - val_mae: 0.0124 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 59: val_loss improved from 0.01312 to 0.01244, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0072, mae=0.0072, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200 - 12.68s - loss: 0.0072 - mae: 0.0072 - val_loss: 0.0120 - val_mae: 0.0120 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 60: val_loss improved from 0.01244 to 0.01196, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00759, mae=0.00759, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200 - 12.71s - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0135 - val_mae: 0.0135 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00753, mae=0.00753, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200 - 12.65s - loss: 0.0075 - mae: 0.0075 - val_loss: 0.0119 - val_mae: 0.0119 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 62: val_loss improved from 0.01196 to 0.01191, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00746, mae=0.00746, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200 - 12.72s - loss: 0.0075 - mae: 0.0075 - val_loss: 0.0131 - val_mae: 0.0131 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00738, mae=0.00738, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200 - 12.65s - loss: 0.0074 - mae: 0.0074 - val_loss: 0.0120 - val_mae: 0.0120 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00712, mae=0.00712, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200 - 12.63s - loss: 0.0071 - mae: 0.0071 - val_loss: 0.0122 - val_mae: 0.0122 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00693, mae=0.00693, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200 - 12.63s - loss: 0.0069 - mae: 0.0069 - val_loss: 0.0119 - val_mae: 0.0119 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 66: val_loss improved from 0.01191 to 0.01189, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00631, mae=0.00631, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200 - 12.69s - loss: 0.0063 - mae: 0.0063 - val_loss: 0.0121 - val_mae: 0.0121 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00615, mae=0.00615, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200 - 12.64s - loss: 0.0062 - mae: 0.0062 - val_loss: 0.0125 - val_mae: 0.0125 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00646, mae=0.00646, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200 - 12.64s - loss: 0.0065 - mae: 0.0065 - val_loss: 0.0117 - val_mae: 0.0117 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 69: val_loss improved from 0.01189 to 0.01171, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00637, mae=0.00637, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200 - 12.68s - loss: 0.0064 - mae: 0.0064 - val_loss: 0.0123 - val_mae: 0.0123 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00587, mae=0.00587, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200 - 12.64s - loss: 0.0059 - mae: 0.0059 - val_loss: 0.0116 - val_mae: 0.0116 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 71: val_loss improved from 0.01171 to 0.01159, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00624, mae=0.00624, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200 - 12.67s - loss: 0.0062 - mae: 0.0062 - val_loss: 0.0122 - val_mae: 0.0122 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00637, mae=0.00637, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200 - 12.68s - loss: 0.0064 - mae: 0.0064 - val_loss: 0.0117 - val_mae: 0.0117 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00567, mae=0.00567, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200 - 12.62s - loss: 0.0057 - mae: 0.0057 - val_loss: 0.0110 - val_mae: 0.0110 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 74: val_loss improved from 0.01159 to 0.01103, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00604, mae=0.00604, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200 - 12.68s - loss: 0.0060 - mae: 0.0060 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00562, mae=0.00562, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200 - 12.63s - loss: 0.0056 - mae: 0.0056 - val_loss: 0.0119 - val_mae: 0.0119 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00565, mae=0.00565, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200 - 12.65s - loss: 0.0057 - mae: 0.0057 - val_loss: 0.0119 - val_mae: 0.0119 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.0061, mae=0.0061, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200 - 12.65s - loss: 0.0061 - mae: 0.0061 - val_loss: 0.0121 - val_mae: 0.0121 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00589, mae=0.00589, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200 - 12.66s - loss: 0.0059 - mae: 0.0059 - val_loss: 0.0114 - val_mae: 0.0114 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00523, mae=0.00523, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200 - 12.65s - loss: 0.0052 - mae: 0.0052 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00527, mae=0.00527, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200 - 12.64s - loss: 0.0053 - mae: 0.0053 - val_loss: 0.0118 - val_mae: 0.0118 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00485, mae=0.00485, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200 - 12.70s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00508, mae=0.00508, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200 - 12.64s - loss: 0.0051 - mae: 0.0051 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00496, mae=0.00496, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200 - 12.66s - loss: 0.0050 - mae: 0.0050 - val_loss: 0.0110 - val_mae: 0.0110 - learning_rate: 1e-05\n",
      "\n",
      "Epoch 84: val_loss improved from 0.01103 to 0.01096, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00489, mae=0.00489, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200 - 12.72s - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00484, mae=0.00484, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200 - 12.67s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1e-05\n",
      "\n",
      "Epoch 86: val_loss improved from 0.01096 to 0.01093, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00502, mae=0.00502, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200 - 12.73s - loss: 0.0050 - mae: 0.0050 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1e-05\n",
      "\n",
      "Epoch 87: val_loss improved from 0.01093 to 0.01092, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00493, mae=0.00493, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200 - 12.70s - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00505, mae=0.00505, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200 - 12.66s - loss: 0.0050 - mae: 0.0050 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00478, mae=0.00478, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200 - 12.66s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00484, mae=0.00484, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200 - 12.67s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0120 - val_mae: 0.0120 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00472, mae=0.00472, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200 - 12.69s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00469, mae=0.00469, lr=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200 - 12.68s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0114 - val_mae: 0.0114 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00477, mae=0.00477, lr=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200 - 12.68s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00475, mae=0.00475, lr=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200 - 12.71s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0046, mae=0.0046, lr=1e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200 - 12.66s - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000002e-06\n",
      "\n",
      "Epoch 96: val_loss improved from 0.01092 to 0.01086, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.0053, mae=0.0053, lr=1e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200 - 12.70s - loss: 0.0053 - mae: 0.0053 - val_loss: 0.0110 - val_mae: 0.0110 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00475, mae=0.00475, lr=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200 - 12.65s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0110 - val_mae: 0.0110 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00486, mae=0.00486, lr=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200 - 12.65s - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0115 - val_mae: 0.0115 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00491, mae=0.00491, lr=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200 - 12.65s - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0114 - val_mae: 0.0114 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00459, mae=0.00459, lr=1e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200 - 12.65s - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00512, mae=0.00512, lr=1e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200 - 12.68s - loss: 0.0051 - mae: 0.0051 - val_loss: 0.0114 - val_mae: 0.0114 - learning_rate: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00463, mae=0.00463, lr=1e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200 - 12.68s - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000002e-07\n",
      "\n",
      "Epoch 103: val_loss improved from 0.01086 to 0.01086, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.0047, mae=0.0047, lr=1e-7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200 - 12.66s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00478, mae=0.00478, lr=1e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200 - 12.67s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0110 - val_mae: 0.0110 - learning_rate: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00447, mae=0.00447, lr=1e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200 - 12.64s - loss: 0.0045 - mae: 0.0045 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00477, mae=0.00477, lr=1e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200 - 12.65s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0117 - val_mae: 0.0117 - learning_rate: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00481, mae=0.00481, lr=1e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200 - 12.67s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00478, mae=0.00478, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200 - 12.67s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.0048, mae=0.0048, lr=1e-8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200 - 12.66s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/200: 100%|██████████| 56/56 [00:11<00:00,  4.82it/s, loss=0.00476, mae=0.00476, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200 - 12.77s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00473, mae=0.00473, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200 - 12.67s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0108 - val_mae: 0.0108 - learning_rate: 1.0000000000000004e-08\n",
      "\n",
      "Epoch 112: val_loss improved from 0.01086 to 0.01083, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/attention1/models/attention1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/200: 100%|██████████| 56/56 [00:11<00:00,  4.81it/s, loss=0.00476, mae=0.00476, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200 - 12.78s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00494, mae=0.00494, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200 - 12.69s - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00466, mae=0.00466, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200 - 12.64s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00452, mae=0.00452, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200 - 12.64s - loss: 0.0045 - mae: 0.0045 - val_loss: 0.0114 - val_mae: 0.0114 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00473, mae=0.00473, lr=1e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200 - 12.66s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00478, mae=0.00478, lr=1e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200 - 12.64s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000005e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00468, mae=0.00468, lr=1e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200 - 12.66s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000005e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00471, mae=0.00471, lr=1e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200 - 12.71s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000005e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00458, mae=0.00458, lr=1e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200 - 12.66s - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0110 - val_mae: 0.0110 - learning_rate: 1.0000000000000005e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/200: 100%|██████████| 56/56 [00:11<00:00,  4.83it/s, loss=0.00507, mae=0.00507, lr=1e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200 - 12.68s - loss: 0.0051 - mae: 0.0051 - val_loss: 0.0110 - val_mae: 0.0110 - learning_rate: 1.0000000000000005e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00465, mae=0.00465, lr=1e-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200 - 12.65s - loss: 0.0046 - mae: 0.0046 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 1.0000000000000006e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00474, mae=0.00474, lr=1e-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200 - 12.65s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 1.0000000000000006e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00478, mae=0.00478, lr=1e-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200 - 12.66s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0111 - val_mae: 0.0111 - learning_rate: 1.0000000000000006e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00475, mae=0.00475, lr=1e-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200 - 12.66s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1.0000000000000006e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00489, mae=0.00489, lr=1e-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200 - 12.67s - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000006e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00473, mae=0.00473, lr=1e-11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200 - 12.66s - loss: 0.0047 - mae: 0.0047 - val_loss: 0.0115 - val_mae: 0.0115 - learning_rate: 1.0000000000000006e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00497, mae=0.00497, lr=1e-11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200 - 12.68s - loss: 0.0050 - mae: 0.0050 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 1.0000000000000006e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00475, mae=0.00475, lr=1e-11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200 - 12.65s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0113 - val_mae: 0.0113 - learning_rate: 1.0000000000000006e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00488, mae=0.00488, lr=1e-11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200 - 12.63s - loss: 0.0049 - mae: 0.0049 - val_loss: 0.0109 - val_mae: 0.0109 - learning_rate: 1.0000000000000006e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/200: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s, loss=0.00479, mae=0.00479, lr=1e-11]\n",
      "Exception ignored in: <function LogFileLogger.__del__ at 0x7f5bc09367a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/src/callbacks/logger.py\", line 96, in __del__\n",
      "    self.close()  # Ensure the file is closed when the object is deleted\n",
      "  File \"/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/src/callbacks/logger.py\", line 92, in close\n",
      "    self.file.write(end_message)\n",
      "ValueError: I/O operation on closed file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200 - 12.66s - loss: 0.0048 - mae: 0.0048 - val_loss: 0.0112 - val_mae: 0.0112 - learning_rate: 1.0000000000000006e-11\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5779"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader = load_data(model_config, data_config)\n",
    "\n",
    "history = create_and_train_model(model_config, train_loader, val_loader)\n",
    "\n",
    "# Clean environment - Delete vars and free GPU memory (there is still something takin like 6% of the GPU V-RAM)\n",
    "del history\n",
    "del model_name\n",
    "del batch_size\n",
    "del data_config\n",
    "del model_config\n",
    "del train_loader\n",
    "del val_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4 - ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Settings ===\n",
      "\u001b[1m - Data Directory Path: \u001b[0m \u001b[3m/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC\u001b[0m\n",
      "\u001b[1m - Using device:       \u001b[0m \u001b[3m cuda\u001b[0m\n",
      "\n",
      "=== Data Configuration ===\n",
      "\u001b[1m - axis_cut:  \u001b[0m \u001b[3maxial\u001b[0m\n",
      "\u001b[1m - first_cut: \u001b[0m \u001b[3m0\u001b[0m\n",
      "\u001b[1m - last_cut:  \u001b[0m \u001b[3m127\u001b[0m\n",
      "\u001b[1m - layer_qty: \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - normalize: \u001b[0m \u001b[3mFalse\u001b[0m\n",
      "\n",
      "=== Model Configuration ===\n",
      "\u001b[1m - name:                    \u001b[0m \u001b[3mvit_pruebas_2\u001b[0m\n",
      "\u001b[1m - model_type:              \u001b[0m \u001b[3mvit\u001b[0m\n",
      "\u001b[1m - input_shape:             \u001b[0m \u001b[3m[1, 8, 128, 128]\u001b[0m\n",
      "\u001b[1m - input_shape_graph:       \u001b[0m \u001b[3m[8, 1, 8, 128, 128]\u001b[0m\n",
      "\u001b[1m - output_channels:         \u001b[0m \u001b[3m1\u001b[0m\n",
      "\u001b[1m - batch_size:              \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - patch_size:              \u001b[0m \u001b[3m16\u001b[0m\n",
      "\u001b[1m - embed_dim:               \u001b[0m \u001b[3m768\u001b[0m\n",
      "\u001b[1m - num_heads:               \u001b[0m \u001b[3m12\u001b[0m\n",
      "\u001b[1m - num_layers:              \u001b[0m \u001b[3m8\u001b[0m\n",
      "\u001b[1m - dropout:                 \u001b[0m \u001b[3m0.15\u001b[0m\n",
      "\u001b[1m - mlp_ratio:               \u001b[0m \u001b[3m2.0\u001b[0m\n",
      "\u001b[1m - layer_dropouts:          \u001b[0m \u001b[3m[0.1, 0.1, 0.12, 0.12, 0.15, 0.15, 0.18, 0.18]\u001b[0m\n",
      "\u001b[1m - overlap_ratio:           \u001b[0m \u001b[3m0.5\u001b[0m\n",
      "\u001b[1m - use_spatial_attention:   \u001b[0m \u001b[3mTrue\u001b[0m\n",
      "\u001b[1m - use_smoothing:           \u001b[0m \u001b[3mTrue\u001b[0m\n",
      "\u001b[1m - num_epochs:              \u001b[0m \u001b[3m200\u001b[0m\n",
      "\u001b[1m - learning_rate:           \u001b[0m \u001b[3m0.0001\u001b[0m\n",
      "\u001b[1m - early_stopping_patience: \u001b[0m \u001b[3m20\u001b[0m\n",
      "\u001b[1m - reduce_lr_patience:      \u001b[0m \u001b[3m4\u001b[0m\n",
      "\u001b[1m - lr_reduce_factor:        \u001b[0m \u001b[3m0.1\u001b[0m\n",
      "\u001b[1m - min_lr:                  \u001b[0m \u001b[3m1e-12\u001b[0m\n",
      "\u001b[1m - save_method:             \u001b[0m \u001b[3mcomplete\u001b[0m\n",
      "\u001b[1m - web_view:                \u001b[0m \u001b[3mFalse\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_name = 'vit_pruebas_2'\n",
    "batch_size = 8\n",
    "layer_qty = 8\n",
    "data_config = {\n",
    "    'axis_cut': IMAGE_CUT_OPTIONS[1],\n",
    "    'first_cut': 0,\n",
    "    'last_cut': 127,\n",
    "    'layer_qty': layer_qty,\n",
    "    'normalize': False\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"name\": model_name,\n",
    "    'model_type': MODEL_TYPE[3],\n",
    "    \"input_shape\": [1, layer_qty, 128, 128],  # (..., channels, height, width)\n",
    "    \"input_shape_graph\": [batch_size, 1, layer_qty, 128, 128],  # (..., channels, height, width)\n",
    "    \"output_channels\": 1,  # Same as input channels\n",
    "    \"batch_size\": batch_size,\n",
    "    \"patch_size\": 16,\n",
    "    \"embed_dim\": 768,\n",
    "    \"num_heads\": 12,\n",
    "    \"num_layers\": 8,\n",
    "    \"dropout\": 0.15,\n",
    "    \"mlp_ratio\": 2.0,\n",
    "    \"layer_dropouts\": [0.1, 0.1, 0.12, 0.12, 0.15, 0.15, 0.18, 0.18],\n",
    "    \"overlap_ratio\": 0.5,            # 50% overlap between patches\n",
    "    \"use_spatial_attention\": True,   # Enable spatial-aware transformer blocks\n",
    "    \"use_smoothing\": True,           # Enable post-processing smoothing\n",
    "    'num_epochs': 200,\n",
    "    'learning_rate': 1e-4,\n",
    "    'early_stopping_patience': 20,\n",
    "    'reduce_lr_patience': 4,\n",
    "    'lr_reduce_factor': 0.1,\n",
    "    'min_lr': 1e-12,\n",
    "    'save_method': MODEL_SAVE_OPTIONS[2],\n",
    "    'web_view': False\n",
    "}\n",
    "\n",
    "display_configurations(model_config, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/config/data_config.json'...\n",
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/config/model_config.json'...\n",
      "Loading training data...\n",
      " ==  Loading train images set  ==\n",
      "\t- Loading 28 images from '/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC/fold1' ...\n",
      "\t- Could only load 28 images. Detected 0 outlier(s)\n",
      "\t- Pixels value range: [0.0, 0.22]\n",
      "Train inputs shape: (448, 1, 8, 128, 128)\n",
      "Train targets shape: (448, 1, 8, 128, 128)\n",
      "Training loader generated. Batch size: 8\n",
      "== Train set loader ==\n",
      "Common batch shape (num_batches / batch_size, channels, depth / num_layers, height, width):\n",
      " - Inputs: torch.Size([8, 1, 8, 128, 128])\n",
      " - Targets: torch.Size([8, 1, 8, 128, 128])\n",
      "All batches have the same size\n",
      "Loading test data for validation...\n",
      " ==  Loading test images set  ==\n",
      "\t- Loading 8 images from '/home/promise/NAS/MATERIA_OSCURA/PROYECTOS_INVESTIGACION/2025-Direct_AC/001-Dataset/002-PET_NAC_AC/fold1' ...\n",
      "\t- Could only load 6 images. Detected 2 outlier(s)\n",
      "\t- Pixels value range: [0.0, 0.23]\n",
      "Splitting test set in half, the second half will be used for validation...\n",
      "Validation inputs shape: (48, 1, 8, 128, 128)\n",
      "Validation targets shape: (48, 1, 8, 128, 128)\n",
      "Validation loader generated. Batch size: 8\n",
      "== Validation set loader ==\n",
      "Common batch shape (num_batches / batch_size, channels, depth / num_layers, height, width):\n",
      " - Inputs: torch.Size([8, 1, 8, 128, 128])\n",
      " - Targets: torch.Size([8, 1, 8, 128, 128])\n",
      "All batches have the same size\n",
      "Configuration saved to: '/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/config/model_config.json'...\n",
      "Warning: 3D input detected, ViT will reshape to process all slices: (B*D, C, H, W)\n",
      "Enhanced ViT Configuration: 225 patches (15x15), 8 transformer blocks, 768 embedding dimension\n",
      "Overlap ratio: 0.5, Effective stride: 8\n",
      "Processing 3D input: flattening 8 slices into batch dimension\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "VisionTransformer                        [1, 1, 8, 128, 128]       173,568\n",
      "├─pos_embed                                                        ├─172,800\n",
      "├─cls_token                                                        └─768\n",
      "├─Conv2d: 1-1                            [8, 768, 15, 15]          197,376\n",
      "│    └─weight                                                      ├─196,608\n",
      "│    └─bias                                                        └─768\n",
      "├─Dropout: 1-2                           [8, 225, 768]             --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─0.norm1.weight                                              ├─768\n",
      "│    └─0.norm1.bias                                                ├─768\n",
      "│    └─0.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─0.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─0.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─0.attn.out_proj.bias                                        ├─768\n",
      "│    └─0.spatial_norm.weight                                       ├─768\n",
      "│    └─0.spatial_norm.bias                                         ├─768\n",
      "│    └─0.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─0.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─0.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─0.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─0.norm2.weight                                              ├─768\n",
      "│    └─0.norm2.bias                                                ├─768\n",
      "│    └─0.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─0.mlp.0.bias                                                ├─1,536\n",
      "│    └─0.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─0.mlp.3.bias                                                ├─768\n",
      "│    └─1.norm1.weight                                              ├─768\n",
      "│    └─1.norm1.bias                                                ├─768\n",
      "│    └─1.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─1.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─1.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─1.attn.out_proj.bias                                        ├─768\n",
      "│    └─1.spatial_norm.weight                                       ├─768\n",
      "│    └─1.spatial_norm.bias                                         ├─768\n",
      "│    └─1.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─1.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─1.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─1.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─1.norm2.weight                                              ├─768\n",
      "│    └─1.norm2.bias                                                ├─768\n",
      "│    └─1.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─1.mlp.0.bias                                                ├─1,536\n",
      "│    └─1.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─1.mlp.3.bias                                                ├─768\n",
      "│    └─2.norm1.weight                                              ├─768\n",
      "│    └─2.norm1.bias                                                ├─768\n",
      "│    └─2.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─2.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─2.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─2.attn.out_proj.bias                                        ├─768\n",
      "│    └─2.spatial_norm.weight                                       ├─768\n",
      "│    └─2.spatial_norm.bias                                         ├─768\n",
      "│    └─2.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─2.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─2.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─2.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─2.norm2.weight                                              ├─768\n",
      "│    └─2.norm2.bias                                                ├─768\n",
      "│    └─2.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─2.mlp.0.bias                                                ├─1,536\n",
      "│    └─2.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─2.mlp.3.bias                                                ├─768\n",
      "│    └─3.norm1.weight                                              ├─768\n",
      "│    └─3.norm1.bias                                                ├─768\n",
      "│    └─3.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─3.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─3.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─3.attn.out_proj.bias                                        ├─768\n",
      "│    └─3.spatial_norm.weight                                       ├─768\n",
      "│    └─3.spatial_norm.bias                                         ├─768\n",
      "│    └─3.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─3.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─3.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─3.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─3.norm2.weight                                              ├─768\n",
      "│    └─3.norm2.bias                                                ├─768\n",
      "│    └─3.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─3.mlp.0.bias                                                ├─1,536\n",
      "│    └─3.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─3.mlp.3.bias                                                ├─768\n",
      "│    └─4.norm1.weight                                              ├─768\n",
      "│    └─4.norm1.bias                                                ├─768\n",
      "│    └─4.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─4.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─4.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─4.attn.out_proj.bias                                        ├─768\n",
      "│    └─4.spatial_norm.weight                                       ├─768\n",
      "│    └─4.spatial_norm.bias                                         ├─768\n",
      "│    └─4.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─4.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─4.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─4.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─4.norm2.weight                                              ├─768\n",
      "│    └─4.norm2.bias                                                ├─768\n",
      "│    └─4.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─4.mlp.0.bias                                                ├─1,536\n",
      "│    └─4.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─4.mlp.3.bias                                                ├─768\n",
      "│    └─5.norm1.weight                                              ├─768\n",
      "│    └─5.norm1.bias                                                ├─768\n",
      "│    └─5.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─5.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─5.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─5.attn.out_proj.bias                                        ├─768\n",
      "│    └─5.spatial_norm.weight                                       ├─768\n",
      "│    └─5.spatial_norm.bias                                         ├─768\n",
      "│    └─5.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─5.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─5.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─5.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─5.norm2.weight                                              ├─768\n",
      "│    └─5.norm2.bias                                                ├─768\n",
      "│    └─5.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─5.mlp.0.bias                                                ├─1,536\n",
      "│    └─5.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─5.mlp.3.bias                                                ├─768\n",
      "│    └─6.norm1.weight                                              ├─768\n",
      "│    └─6.norm1.bias                                                ├─768\n",
      "│    └─6.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─6.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─6.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─6.attn.out_proj.bias                                        ├─768\n",
      "│    └─6.spatial_norm.weight                                       ├─768\n",
      "│    └─6.spatial_norm.bias                                         ├─768\n",
      "│    └─6.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─6.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─6.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─6.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─6.norm2.weight                                              ├─768\n",
      "│    └─6.norm2.bias                                                ├─768\n",
      "│    └─6.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─6.mlp.0.bias                                                ├─1,536\n",
      "│    └─6.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─6.mlp.3.bias                                                ├─768\n",
      "│    └─7.norm1.weight                                              ├─768\n",
      "│    └─7.norm1.bias                                                ├─768\n",
      "│    └─7.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─7.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─7.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─7.attn.out_proj.bias                                        ├─768\n",
      "│    └─7.spatial_norm.weight                                       ├─768\n",
      "│    └─7.spatial_norm.bias                                         ├─768\n",
      "│    └─7.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─7.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─7.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─7.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─7.norm2.weight                                              ├─768\n",
      "│    └─7.norm2.bias                                                ├─768\n",
      "│    └─7.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─7.mlp.0.bias                                                ├─1,536\n",
      "│    └─7.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─7.mlp.3.bias                                                └─768\n",
      "│    └─SpatialTransformerBlock: 2-1      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-1               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-2      [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-3               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-4      [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-5               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-6              [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-1             [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-2               [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-3            [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-4             [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-5            [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-2      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-7               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-8      [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-9               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-10     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-11              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-12             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-6             [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-7               [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-8            [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-9             [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-10           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-3      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-13              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-14     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-15              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-16     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-17              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-18             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-11            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-12              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-13           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-14            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-15           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-4      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-19              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-20     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-21              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-22     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-23              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-24             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-16            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-17              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-18           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-19            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-20           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-5      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-25              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-26     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-27              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-28     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-29              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-30             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-21            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-22              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-23           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-24            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-25           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-6      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-31              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-32     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-33              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-34     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-35              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-36             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-26            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-27              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-28           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-29            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-30           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-7      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-37              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-38     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-39              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-40     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-41              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-42             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-31            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-32              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-33           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-34            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-35           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-8      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-43              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-44     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-45              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-46     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-47              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-48             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-36            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-37              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-38           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-39            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-40           [8, 225, 768]             --\n",
      "├─LayerNorm: 1-4                         [8, 225, 768]             1,536\n",
      "│    └─weight                                                      ├─768\n",
      "│    └─bias                                                        └─768\n",
      "├─Sequential: 1-5                        [8, 225, 256]             --\n",
      "│    └─0.weight                                                    ├─1,179,648\n",
      "│    └─0.bias                                                      ├─1,536\n",
      "│    └─3.weight                                                    ├─393,216\n",
      "│    └─3.bias                                                      └─256\n",
      "│    └─Linear: 2-9                       [8, 225, 1536]            1,181,184\n",
      "│    │    └─weight                                                 ├─1,179,648\n",
      "│    │    └─bias                                                   └─1,536\n",
      "│    └─GELU: 2-10                        [8, 225, 1536]            --\n",
      "│    └─Dropout: 2-11                     [8, 225, 1536]            --\n",
      "│    └─Linear: 2-12                      [8, 225, 256]             393,472\n",
      "│    │    └─weight                                                 ├─393,216\n",
      "│    │    └─bias                                                   └─256\n",
      "│    └─Tanh: 2-13                        [8, 225, 256]             --\n",
      "==========================================================================================\n",
      "Total params: 58,674,688\n",
      "Trainable params: 58,674,688\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 519.32\n",
      "==========================================================================================\n",
      "Input size (MB): 0.52\n",
      "Forward/backward pass size (MB): 578.76\n",
      "Params size (MB): 82.81\n",
      "Estimated Total Size (MB): 662.10\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "VisionTransformer                        [1, 1, 8, 128, 128]       173,568\n",
      "├─pos_embed                                                        ├─172,800\n",
      "├─cls_token                                                        └─768\n",
      "├─Conv2d: 1-1                            [8, 768, 15, 15]          197,376\n",
      "│    └─weight                                                      ├─196,608\n",
      "│    └─bias                                                        └─768\n",
      "├─Dropout: 1-2                           [8, 225, 768]             --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─0.norm1.weight                                              ├─768\n",
      "│    └─0.norm1.bias                                                ├─768\n",
      "│    └─0.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─0.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─0.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─0.attn.out_proj.bias                                        ├─768\n",
      "│    └─0.spatial_norm.weight                                       ├─768\n",
      "│    └─0.spatial_norm.bias                                         ├─768\n",
      "│    └─0.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─0.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─0.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─0.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─0.norm2.weight                                              ├─768\n",
      "│    └─0.norm2.bias                                                ├─768\n",
      "│    └─0.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─0.mlp.0.bias                                                ├─1,536\n",
      "│    └─0.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─0.mlp.3.bias                                                ├─768\n",
      "│    └─1.norm1.weight                                              ├─768\n",
      "│    └─1.norm1.bias                                                ├─768\n",
      "│    └─1.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─1.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─1.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─1.attn.out_proj.bias                                        ├─768\n",
      "│    └─1.spatial_norm.weight                                       ├─768\n",
      "│    └─1.spatial_norm.bias                                         ├─768\n",
      "│    └─1.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─1.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─1.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─1.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─1.norm2.weight                                              ├─768\n",
      "│    └─1.norm2.bias                                                ├─768\n",
      "│    └─1.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─1.mlp.0.bias                                                ├─1,536\n",
      "│    └─1.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─1.mlp.3.bias                                                ├─768\n",
      "│    └─2.norm1.weight                                              ├─768\n",
      "│    └─2.norm1.bias                                                ├─768\n",
      "│    └─2.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─2.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─2.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─2.attn.out_proj.bias                                        ├─768\n",
      "│    └─2.spatial_norm.weight                                       ├─768\n",
      "│    └─2.spatial_norm.bias                                         ├─768\n",
      "│    └─2.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─2.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─2.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─2.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─2.norm2.weight                                              ├─768\n",
      "│    └─2.norm2.bias                                                ├─768\n",
      "│    └─2.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─2.mlp.0.bias                                                ├─1,536\n",
      "│    └─2.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─2.mlp.3.bias                                                ├─768\n",
      "│    └─3.norm1.weight                                              ├─768\n",
      "│    └─3.norm1.bias                                                ├─768\n",
      "│    └─3.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─3.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─3.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─3.attn.out_proj.bias                                        ├─768\n",
      "│    └─3.spatial_norm.weight                                       ├─768\n",
      "│    └─3.spatial_norm.bias                                         ├─768\n",
      "│    └─3.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─3.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─3.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─3.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─3.norm2.weight                                              ├─768\n",
      "│    └─3.norm2.bias                                                ├─768\n",
      "│    └─3.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─3.mlp.0.bias                                                ├─1,536\n",
      "│    └─3.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─3.mlp.3.bias                                                ├─768\n",
      "│    └─4.norm1.weight                                              ├─768\n",
      "│    └─4.norm1.bias                                                ├─768\n",
      "│    └─4.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─4.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─4.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─4.attn.out_proj.bias                                        ├─768\n",
      "│    └─4.spatial_norm.weight                                       ├─768\n",
      "│    └─4.spatial_norm.bias                                         ├─768\n",
      "│    └─4.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─4.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─4.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─4.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─4.norm2.weight                                              ├─768\n",
      "│    └─4.norm2.bias                                                ├─768\n",
      "│    └─4.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─4.mlp.0.bias                                                ├─1,536\n",
      "│    └─4.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─4.mlp.3.bias                                                ├─768\n",
      "│    └─5.norm1.weight                                              ├─768\n",
      "│    └─5.norm1.bias                                                ├─768\n",
      "│    └─5.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─5.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─5.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─5.attn.out_proj.bias                                        ├─768\n",
      "│    └─5.spatial_norm.weight                                       ├─768\n",
      "│    └─5.spatial_norm.bias                                         ├─768\n",
      "│    └─5.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─5.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─5.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─5.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─5.norm2.weight                                              ├─768\n",
      "│    └─5.norm2.bias                                                ├─768\n",
      "│    └─5.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─5.mlp.0.bias                                                ├─1,536\n",
      "│    └─5.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─5.mlp.3.bias                                                ├─768\n",
      "│    └─6.norm1.weight                                              ├─768\n",
      "│    └─6.norm1.bias                                                ├─768\n",
      "│    └─6.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─6.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─6.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─6.attn.out_proj.bias                                        ├─768\n",
      "│    └─6.spatial_norm.weight                                       ├─768\n",
      "│    └─6.spatial_norm.bias                                         ├─768\n",
      "│    └─6.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─6.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─6.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─6.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─6.norm2.weight                                              ├─768\n",
      "│    └─6.norm2.bias                                                ├─768\n",
      "│    └─6.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─6.mlp.0.bias                                                ├─1,536\n",
      "│    └─6.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─6.mlp.3.bias                                                ├─768\n",
      "│    └─7.norm1.weight                                              ├─768\n",
      "│    └─7.norm1.bias                                                ├─768\n",
      "│    └─7.attn.in_proj_weight                                       ├─1,769,472\n",
      "│    └─7.attn.in_proj_bias                                         ├─2,304\n",
      "│    └─7.attn.out_proj.weight                                      ├─589,824\n",
      "│    └─7.attn.out_proj.bias                                        ├─768\n",
      "│    └─7.spatial_norm.weight                                       ├─768\n",
      "│    └─7.spatial_norm.bias                                         ├─768\n",
      "│    └─7.spatial_attn.in_proj_weight                               ├─1,769,472\n",
      "│    └─7.spatial_attn.in_proj_bias                                 ├─2,304\n",
      "│    └─7.spatial_attn.out_proj.weight                              ├─589,824\n",
      "│    └─7.spatial_attn.out_proj.bias                                ├─768\n",
      "│    └─7.norm2.weight                                              ├─768\n",
      "│    └─7.norm2.bias                                                ├─768\n",
      "│    └─7.mlp.0.weight                                              ├─1,179,648\n",
      "│    └─7.mlp.0.bias                                                ├─1,536\n",
      "│    └─7.mlp.3.weight                                              ├─1,179,648\n",
      "│    └─7.mlp.3.bias                                                └─768\n",
      "│    └─SpatialTransformerBlock: 2-1      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-1               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-2      [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-3               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-4      [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-5               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-6              [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-1             [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-2               [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-3            [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-4             [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-5            [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-2      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-7               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-8      [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-9               [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-10     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-11              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-12             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-6             [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-7               [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-8            [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-9             [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-10           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-3      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-13              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-14     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-15              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-16     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-17              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-18             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-11            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-12              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-13           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-14            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-15           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-4      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-19              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-20     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-21              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-22     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-23              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-24             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-16            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-17              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-18           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-19            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-20           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-5      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-25              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-26     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-27              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-28     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-29              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-30             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-21            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-22              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-23           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-24            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-25           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-6      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-31              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-32     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-33              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-34     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-35              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-36             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-26            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-27              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-28           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-29            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-30           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-7      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-37              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-38     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-39              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-40     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-41              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-42             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-31            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-32              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-33           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-34            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-35           [8, 225, 768]             --\n",
      "│    └─SpatialTransformerBlock: 2-8      [8, 225, 768]             --\n",
      "│    │    └─norm1.weight                                           ├─768\n",
      "│    │    └─norm1.bias                                             ├─768\n",
      "│    │    └─attn.in_proj_weight                                    ├─1,769,472\n",
      "│    │    └─attn.in_proj_bias                                      ├─2,304\n",
      "│    │    └─attn.out_proj.weight                                   ├─589,824\n",
      "│    │    └─attn.out_proj.bias                                     ├─768\n",
      "│    │    └─spatial_norm.weight                                    ├─768\n",
      "│    │    └─spatial_norm.bias                                      ├─768\n",
      "│    │    └─spatial_attn.in_proj_weight                            ├─1,769,472\n",
      "│    │    └─spatial_attn.in_proj_bias                              ├─2,304\n",
      "│    │    └─spatial_attn.out_proj.weight                           ├─589,824\n",
      "│    │    └─spatial_attn.out_proj.bias                             ├─768\n",
      "│    │    └─norm2.weight                                           ├─768\n",
      "│    │    └─norm2.bias                                             ├─768\n",
      "│    │    └─mlp.0.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.0.bias                                             ├─1,536\n",
      "│    │    └─mlp.3.weight                                           ├─1,179,648\n",
      "│    │    └─mlp.3.bias                                             └─768\n",
      "│    │    └─LayerNorm: 3-43              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-44     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-45              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─MultiheadAttention: 3-46     [8, 225, 768]             2,362,368\n",
      "│    │    │    └─in_proj_weight                                    ├─1,769,472\n",
      "│    │    │    └─in_proj_bias                                      ├─2,304\n",
      "│    │    │    └─out_proj.weight                                   ├─589,824\n",
      "│    │    │    └─out_proj.bias                                     └─768\n",
      "│    │    └─LayerNorm: 3-47              [8, 225, 768]             1,536\n",
      "│    │    │    └─weight                                            ├─768\n",
      "│    │    │    └─bias                                              └─768\n",
      "│    │    └─Sequential: 3-48             [8, 225, 768]             --\n",
      "│    │    │    └─0.weight                                          ├─1,179,648\n",
      "│    │    │    └─0.bias                                            ├─1,536\n",
      "│    │    │    └─3.weight                                          ├─1,179,648\n",
      "│    │    │    └─3.bias                                            └─768\n",
      "│    │    │    └─Linear: 4-36            [8, 225, 1536]            1,181,184\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─1,536\n",
      "│    │    │    └─GELU: 4-37              [8, 225, 1536]            --\n",
      "│    │    │    └─Dropout: 4-38           [8, 225, 1536]            --\n",
      "│    │    │    └─Linear: 4-39            [8, 225, 768]             1,180,416\n",
      "│    │    │    │    └─weight                                       ├─1,179,648\n",
      "│    │    │    │    └─bias                                         └─768\n",
      "│    │    │    └─Dropout: 4-40           [8, 225, 768]             --\n",
      "├─LayerNorm: 1-4                         [8, 225, 768]             1,536\n",
      "│    └─weight                                                      ├─768\n",
      "│    └─bias                                                        └─768\n",
      "├─Sequential: 1-5                        [8, 225, 256]             --\n",
      "│    └─0.weight                                                    ├─1,179,648\n",
      "│    └─0.bias                                                      ├─1,536\n",
      "│    └─3.weight                                                    ├─393,216\n",
      "│    └─3.bias                                                      └─256\n",
      "│    └─Linear: 2-9                       [8, 225, 1536]            1,181,184\n",
      "│    │    └─weight                                                 ├─1,179,648\n",
      "│    │    └─bias                                                   └─1,536\n",
      "│    └─GELU: 2-10                        [8, 225, 1536]            --\n",
      "│    └─Dropout: 2-11                     [8, 225, 1536]            --\n",
      "│    └─Linear: 2-12                      [8, 225, 256]             393,472\n",
      "│    │    └─weight                                                 ├─393,216\n",
      "│    │    └─bias                                                   └─256\n",
      "│    └─Tanh: 2-13                        [8, 225, 256]             --\n",
      "==========================================================================================\n",
      "Total params: 58,674,688\n",
      "Trainable params: 58,674,688\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 519.32\n",
      "==========================================================================================\n",
      "Input size (MB): 0.52\n",
      "Forward/backward pass size (MB): 578.76\n",
      "Params size (MB): 82.81\n",
      "Estimated Total Size (MB): 662.10\n",
      "==========================================================================================\n",
      "Total trainable parameters: 58,674,688\n",
      "LogFileLogger(filepath=/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/logs/model_train.log, flush_interval=1)\n",
      "ModelCheckpoint(filepath=/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth, monitor=val_loss, verbose=True, save_best_only='True', mode=min, save_method=complete)\n",
      "ReduceLROnPlateau(optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), mode=min, factor=0.1, patience='4', verbose=False, min_lr=1e-12)\n",
      "EarlyStopping(patience=20, verbose=False, delta=0.0, filepath='/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/checkpoints/vit_pruebas_2.pt', restore_best_weights=False)\n",
      "CSVLogger(filepath=/home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/logs/model_train.csv)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 56/56 [04:13<00:00,  4.52s/it, loss=0.0551, mae=0.0551, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 - 257.69s - loss: 0.0551 - mae: 0.0551 - val_loss: 0.0406 - val_mae: 0.0406 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.04058, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|██████████| 56/56 [04:12<00:00,  4.52s/it, loss=0.0304, mae=0.0304, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 - 257.33s - loss: 0.0304 - mae: 0.0304 - val_loss: 0.0235 - val_mae: 0.0235 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 2: val_loss improved from 0.04058 to 0.02355, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0197, mae=0.0197, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200 - 257.19s - loss: 0.0197 - mae: 0.0197 - val_loss: 0.0279 - val_mae: 0.0279 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|██████████| 56/56 [04:13<00:00,  4.52s/it, loss=0.0176, mae=0.0176, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200 - 257.74s - loss: 0.0176 - mae: 0.0176 - val_loss: 0.0195 - val_mae: 0.0195 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 4: val_loss improved from 0.02355 to 0.01951, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|██████████| 56/56 [04:13<00:00,  4.52s/it, loss=0.0166, mae=0.0166, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200 - 257.75s - loss: 0.0166 - mae: 0.0166 - val_loss: 0.0198 - val_mae: 0.0198 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|██████████| 56/56 [04:12<00:00,  4.52s/it, loss=0.0158, mae=0.0158, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200 - 257.29s - loss: 0.0158 - mae: 0.0158 - val_loss: 0.0216 - val_mae: 0.0216 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|██████████| 56/56 [04:13<00:00,  4.52s/it, loss=0.0155, mae=0.0155, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200 - 257.63s - loss: 0.0155 - mae: 0.0155 - val_loss: 0.0213 - val_mae: 0.0213 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.015, mae=0.015, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200 - 256.80s - loss: 0.0150 - mae: 0.0150 - val_loss: 0.0187 - val_mae: 0.0187 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 8: val_loss improved from 0.01951 to 0.01875, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|██████████| 56/56 [04:11<00:00,  4.49s/it, loss=0.0148, mae=0.0148, lr=0.0001] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200 - 256.07s - loss: 0.0148 - mae: 0.0148 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|██████████| 56/56 [04:12<00:00,  4.50s/it, loss=0.0143, mae=0.0143, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 - 256.37s - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0192 - val_mae: 0.0192 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0143, mae=0.0143, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200 - 257.01s - loss: 0.0143 - mae: 0.0143 - val_loss: 0.0194 - val_mae: 0.0194 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|██████████| 56/56 [04:11<00:00,  4.50s/it, loss=0.0141, mae=0.0141, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200 - 256.38s - loss: 0.0141 - mae: 0.0141 - val_loss: 0.0187 - val_mae: 0.0187 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 12: val_loss improved from 0.01875 to 0.01872, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|██████████| 56/56 [04:12<00:00,  4.52s/it, loss=0.0138, mae=0.0138, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200 - 257.34s - loss: 0.0138 - mae: 0.0138 - val_loss: 0.0186 - val_mae: 0.0186 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 13: val_loss improved from 0.01872 to 0.01861, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0129, mae=0.0129, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200 - 257.14s - loss: 0.0129 - mae: 0.0129 - val_loss: 0.0171 - val_mae: 0.0171 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 14: val_loss improved from 0.01861 to 0.01715, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0126, mae=0.0126, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200 - 256.96s - loss: 0.0126 - mae: 0.0126 - val_loss: 0.0170 - val_mae: 0.0170 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 15: val_loss improved from 0.01715 to 0.01705, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0118, mae=0.0118, lr=0.0001] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200 - 257.05s - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0164 - val_mae: 0.0164 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 16: val_loss improved from 0.01705 to 0.01644, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0119, mae=0.0119, lr=0.0001] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200 - 257.09s - loss: 0.0119 - mae: 0.0119 - val_loss: 0.0164 - val_mae: 0.0164 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 17: val_loss improved from 0.01644 to 0.01636, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0118, mae=0.0118, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200 - 257.16s - loss: 0.0118 - mae: 0.0118 - val_loss: 0.0160 - val_mae: 0.0160 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 18: val_loss improved from 0.01636 to 0.01596, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 100%|██████████| 56/56 [04:13<00:00,  4.52s/it, loss=0.0107, mae=0.0107, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200 - 257.60s - loss: 0.0107 - mae: 0.0107 - val_loss: 0.0170 - val_mae: 0.0170 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0105, mae=0.0105, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200 - 256.97s - loss: 0.0105 - mae: 0.0105 - val_loss: 0.0153 - val_mae: 0.0153 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 20: val_loss improved from 0.01596 to 0.01525, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 100%|██████████| 56/56 [04:12<00:00,  4.52s/it, loss=0.0101, mae=0.0101, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200 - 257.28s - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0155 - val_mae: 0.0155 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0101, mae=0.0101, lr=0.0001] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200 - 257.19s - loss: 0.0101 - mae: 0.0101 - val_loss: 0.0150 - val_mae: 0.0150 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 22: val_loss improved from 0.01525 to 0.01495, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.0106, mae=0.0106, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200 - 256.83s - loss: 0.0106 - mae: 0.0106 - val_loss: 0.0167 - val_mae: 0.0167 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.00959, mae=0.00959, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200 - 256.66s - loss: 0.0096 - mae: 0.0096 - val_loss: 0.0148 - val_mae: 0.0148 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 24: val_loss improved from 0.01495 to 0.01481, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 100%|██████████| 56/56 [04:12<00:00,  4.50s/it, loss=0.00955, mae=0.00955, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200 - 256.60s - loss: 0.0095 - mae: 0.0095 - val_loss: 0.0147 - val_mae: 0.0147 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 25: val_loss improved from 0.01481 to 0.01472, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 100%|██████████| 56/56 [04:11<00:00,  4.49s/it, loss=0.00911, mae=0.00911, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200 - 255.64s - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0160 - val_mae: 0.0160 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 100%|██████████| 56/56 [04:11<00:00,  4.50s/it, loss=0.00974, mae=0.00974, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200 - 256.11s - loss: 0.0097 - mae: 0.0097 - val_loss: 0.0143 - val_mae: 0.0143 - learning_rate: 0.0001\n",
      "\n",
      "Epoch 27: val_loss improved from 0.01472 to 0.01434, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.00919, mae=0.00919, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200 - 256.79s - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0147 - val_mae: 0.0147 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.00919, mae=0.00919, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200 - 257.11s - loss: 0.0092 - mae: 0.0092 - val_loss: 0.0157 - val_mae: 0.0157 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 100%|██████████| 56/56 [04:13<00:00,  4.52s/it, loss=0.0091, mae=0.0091, lr=0.0001]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200 - 257.53s - loss: 0.0091 - mae: 0.0091 - val_loss: 0.0144 - val_mae: 0.0144 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.00882, mae=0.00882, lr=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200 - 257.19s - loss: 0.0088 - mae: 0.0088 - val_loss: 0.0150 - val_mae: 0.0150 - learning_rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200: 100%|██████████| 56/56 [04:12<00:00,  4.52s/it, loss=0.00763, mae=0.00763, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200 - 257.26s - loss: 0.0076 - mae: 0.0076 - val_loss: 0.0134 - val_mae: 0.0134 - learning_rate: 1e-05\n",
      "\n",
      "Epoch 32: val_loss improved from 0.01434 to 0.01335, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 100%|██████████| 56/56 [04:12<00:00,  4.51s/it, loss=0.00739, mae=0.00739, lr=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200 - 256.69s - loss: 0.0074 - mae: 0.0074 - val_loss: 0.0133 - val_mae: 0.0133 - learning_rate: 1e-05\n",
      "\n",
      "Epoch 33: val_loss improved from 0.01335 to 0.01325, saving model to /home/promise/jhernandez/3d-notebooks/3d/9jun25/9jun25/models/vit_pruebas_2/models/vit_pruebas_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200:  80%|████████  | 45/56 [03:22<00:49,  4.52s/it, loss=0.00732, mae=0.00732, lr=1e-5]"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = load_data(model_config, data_config)\n",
    "\n",
    "history = create_and_train_model(model_config, train_loader, val_loader)\n",
    "\n",
    "# Clean environment - Delete vars and free GPU memory (there is still something takin like 6% of the GPU V-RAM)\n",
    "del history\n",
    "del model_name\n",
    "del batch_size\n",
    "del data_config\n",
    "del model_config\n",
    "del train_loader\n",
    "del val_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (direct_venv)",
   "language": "python",
   "name": "direct_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
